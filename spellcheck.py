from fsa import FSA
from fst import FST
import numpy as np
import json


def build_editfst(alphabet, counts):
    """Build a weighted FST instance that implements one-edit-distance operations.

    You should use the add_transition() method of the FST class
    to build an FST that returns all misspellings of a word
    with one-edit-distance away.

    The transition weight should be set based on the number of times
    particular edit operations were observed in the data (e.g.,
    spelling-data.txt). You are recommended to estimate (smoothed)
    probabilities for each edit operation, and use its logarithm.
    You are free to experiment with weighting schemes, but remember
    that the transduce() method of FST assumes additive weights.

    Arguments:
    ----
    alphabet    All letters that we should recognize
    counts      Alignment counts generated by compute-weights.py
    """

    fst = FST()
    for letter in alphabet:
        p1 = np.log10((counts[letter][letter] / sum(list(counts[letter].values()))) + 1)

        # identity transitions of all letters
        fst.add_transition(s1=0, insym=letter, s2=0, outsym=letter,
                           w=p1, accepting=False)
        fst.add_transition(s1=1, insym=letter, s2=1, outsym=letter,
                           w=p1, accepting=True)
        # insertion
        fst.add_transition(s1=0, insym="", s2=1, outsym=letter,
                           w=np.log10((counts[""][letter] / sum(list(counts[""].values()))) + 1), accepting=True)
        # deletion
        fst.add_transition(s1=0, insym=letter, s2=1, outsym="",
                           w=np.log10((counts[letter][""] / sum(list(counts[letter].values()))) + 1), accepting=True)

        for letter2 in alphabet:
            if letter != letter2:
                # replacement of any letter with any other
                p2 = np.log10((counts[letter][letter2] / sum(list(counts[letter].values()))) + 1)
                fst.add_transition(s1=0, insym=letter, s2=1, outsym=letter2, w=p2, accepting=True)

    return fst


if __name__ == "__main__":
    ## Example usage
    with open('train_data/lexicon.txt', 'rt') as f:
        words = f.read().strip().split()
        letters = set("".join(words))

    with open('spell-errors.json', 'rt') as f:
        errcount = json.loads(f.read())

    # Build the trie lexicon
    fsa = FSA(deterministic=True)
    fsa.build_trie(words)

    # Minimize it
    print(1)
    # fsa.minimize()
    print(2)
    lexicon = FST.fromfsa(fsa)

    # Convert it to an FST
    # Build the edit-distance FST
    # m1 = fst built from the lexicon
    # m2 = edit fst
    edits = build_editfst(letters, errcount)
    print(3)

    # Compose them
    spellfst = FST.compose_fst(lexicon, edits)
    print(4)

    # The above generates all spelling mistakes, we want the invert
    spellfst.invert()
    spellfst.transduce("wort")
    # for sperr, w in sorted(spellfst.transduce("wort"),
    #                        key=lambda x: x[1], reverse=True):
    #     print(sperr, w)
